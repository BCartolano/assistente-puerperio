# Monitoramento de Testes Mobile - Logs e M√©tricas

**Criado por:** Winston (Architect)  
**Data:** 2025-01-27  
**Vers√£o:** 1.0  
**Status:** ‚úÖ Aprovado

---

## üîç MONITORAMENTO DE LOGS DE CONTEXTO

### **Arquivo: `logs/context_metrics.log`**

**Formato de Log:**
```
2025-01-27 17:00:00 | cansa√ßo_extremo
2025-01-27 17:01:23 | ansiedade
2025-01-27 17:02:45 | d√∫vida_vacina
```

**Como Verificar:**

```bash
# Ver √∫ltimos 20 logs
tail -n 20 logs/context_metrics.log

# Ver logs em tempo real (durante testes)
tail -f logs/context_metrics.log

# Contar frequ√™ncia de tags
cat logs/context_metrics.log | cut -d'|' -f2 | sort | uniq -c | sort -rn
```

**O que observar durante testes mobile:**
- ‚úÖ Tags sendo detectadas corretamente (n√£o apenas vazias)
- ‚úÖ Tags espec√≠ficas aparecem (ex: `cansa√ßo_extremo`, `d√∫vida_vacina`)
- ‚úÖ Timestamps corretos (timezone do servidor)
- ‚ö†Ô∏è Se N√ÉO houver tags detectadas, pode indicar problema na detec√ß√£o

---

## üîß VERIFICA√á√ÉO DE CANCELAMENTO DE REQUISI√á√ïES

### **Monitoramento de Requisi√ß√µes Ativas:**

**Backend (Flask):**
```python
# Em backend/app.py, adicionar log quando requisi√ß√£o √© recebida/cancelada
@app.route('/api/chat', methods=['POST'])
def api_chat():
    logger.info(f"[API_CHAT] Requisi√ß√£o recebida de {request.remote_addr}")
    # ... c√≥digo existente ...
```

**Frontend (Console do Navegador):**
```javascript
// Em api-client.js, logs j√° existem:
console.log('[APIClient] üõë Cancelando requisi√ß√£o para /api/chat');
console.log('[APIClient] ‚úÖ Todas as requisi√ß√µes canceladas');
```

### **Verificar Durante Testes:**

1. **Abrir DevTools (F12) ‚Üí Console**
2. **Trocar rapidamente entre abas (Chat ‚Üí Vacinas ‚Üí Chat)**
3. **Observar logs:**
   - ‚úÖ `[APIClient] üõë Cancelando requisi√ß√£o` aparece quando troca de aba
   - ‚úÖ `[APIClient] ‚úÖ Todas as requisi√ß√µes canceladas` confirma cancelamento
   - ‚ö†Ô∏è Se N√ÉO aparecer, requisi√ß√µes podem estar sendo mantidas na mem√≥ria

### **Monitoramento de Carga do Servidor:**

**Verificar conex√µes abertas:**
```bash
# Linux/Mac (se dispon√≠vel)
netstat -an | grep :5000 | wc -l

# Ou via Python (adicionar ao app.py)
import psutil
connections = psutil.net_connections()
flask_conns = [c for c in connections if c.laddr.port == 5000]
print(f"Conex√µes Flask ativas: {len(flask_conns)}")
```

**Durante testes:**
- ‚úÖ N√∫mero de conex√µes n√£o aumenta descontroladamente
- ‚úÖ Conex√µes fecham ap√≥s requisi√ß√£o completa
- ‚ö†Ô∏è Se conex√µes acumularem, `cancelAll()` pode n√£o estar funcionando

---

## üìä SISTEMA DE LOGGING PARA TESTES

### **Arquivo de Log: `logs/test_metrics.log`** (criar se necess√°rio)

**Formato:**
```json
{
    "timestamp": "2025-01-27T17:00:00Z",
    "test_type": "mobile_navigation",
    "event": "switch_section",
    "from": "chat",
    "to": "vacinas",
    "requests_cancelled": 1,
    "memory_usage_mb": 45.2,
    "connection_count": 2
}
```

### **Implementa√ß√£o Recomendada:**

```python
# Em backend/app.py, adicionar endpoint para logging de testes
@app.route('/api/test-log', methods=['POST'])
def test_log():
    """Endpoint para registrar m√©tricas de testes mobile"""
    data = request.json
    log_file = os.path.join('logs', 'test_metrics.log')
    
    os.makedirs('logs', exist_ok=True)
    
    with open(log_file, 'a', encoding='utf-8') as f:
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            **data
        }
        f.write(json.dumps(log_entry) + '\n')
    
    return jsonify({'status': 'logged'}), 200
```

---

## üîç VERIFICA√á√ÉO DE STREAMING ADAPTATIVO (15ms)

### **Monitoramento no Console do Navegador:**

**Durante teste:**
1. Abrir DevTools ‚Üí Console
2. Enviar mensagem no mobile
3. Observar logs:
   - ‚úÖ `[STREAMING] Delay alto: XXXms` (se aparecer, indica problema)
   - ‚úÖ Se N√ÉO aparecer, streaming est√° funcionando corretamente

**Adicionar logging estruturado:**

```javascript
// Em chat.js, m√©todo typewriterEffect
async typewriterEffect(element, text, speed = 25) {
    const isMobile = window.innerWidth <= 1023;
    const streamingSpeed = isMobile ? 15 : 25;
    
    const startTime = performance.now();
    let errorCount = 0;
    const delays = [];
    
    for (let i = 0; i < text.length; i++) {
        const charStart = performance.now();
        element.textContent += text[i];
        
        if (i < text.length - 1) {
            await new Promise(resolve => setTimeout(resolve, streamingSpeed));
            const charEnd = performance.now();
            const actualDelay = charEnd - charStart;
            delays.push(actualDelay);
            
            // Se delay muito alto (> 2x esperado), loga warning
            if (actualDelay > streamingSpeed * 2) {
                console.warn(`[STREAMING] Delay alto: ${actualDelay.toFixed(2)}ms (esperado: ${streamingSpeed}ms)`);
                errorCount++;
            }
        }
    }
    
    const totalTime = performance.now() - startTime;
    
    // Log estruturado (apenas em desenvolvimento)
    if (window.DEBUG_MODE) {
        console.log({
            event: 'streaming_complete',
            device: isMobile ? 'mobile' : 'desktop',
            speed: streamingSpeed,
            textLength: text.length,
            totalTime: totalTime.toFixed(2),
            avgDelay: (delays.reduce((a, b) => a + b, 0) / delays.length).toFixed(2),
            errors: errorCount
        });
    }
}
```

---

## üìà M√âTRICAS A COLETAR DURANTE TESTES

### **1. Performance:**
- Tempo de resposta da API (ms)
- Tempo de streaming (ms)
- Delay m√©dio por caractere (ms)
- N√∫mero de erros de streaming

### **2. Rede:**
- Tipo de conex√£o (2G, 3G, 4G, 5G)
- Velocidade m√©dia (Mbps)
- Taxa de erros (%)

### **3. Mem√≥ria:**
- Uso de mem√≥ria JavaScript (MB)
- N√∫mero de conex√µes ativas
- Requisi√ß√µes canceladas

### **4. UX:**
- Tarefas completadas (%)
- Tempo m√©dio por tarefa (s)
- Elementos inacess√≠veis

---

## ‚úÖ CHECKLIST DE MONITORAMENTO

### **Pr√©-Teste:**
- [ ] Arquivo `logs/context_metrics.log` existe e tem permiss√£o de escrita
- [ ] DevTools aberto no navegador (Console)
- [ ] `tail -f logs/context_metrics.log` rodando no terminal
- [ ] `DEBUG_MODE = true` definido (se necess√°rio)

### **Durante Teste:**
- [ ] Verificar se tags de contexto aparecem em `context_metrics.log`
- [ ] Verificar se logs de cancelamento aparecem no Console
- [ ] Monitorar n√∫mero de conex√µes ativas
- [ ] Observar erros de streaming (se houver)

### **P√≥s-Teste:**
- [ ] Analisar frequ√™ncia de tags em `context_metrics.log`
- [ ] Verificar se conex√µes foram fechadas corretamente
- [ ] Documentar problemas encontrados
- [ ] Compartilhar m√©tricas com equipe

---

## üìù PR√ìXIMOS PASSOS

1. **Durante testes:** Monitorar logs em tempo real
2. **Ap√≥s testes:** Analisar m√©tricas coletadas
3. **Ajustes:** Corrigir problemas identificados
4. **Valida√ß√£o:** Confirmar melhorias

---

**Vers√£o:** 1.0  
**Status:** ‚úÖ Aprovado  
**Pr√≥xima Revis√£o:** Ap√≥s testes em dispositivo real
