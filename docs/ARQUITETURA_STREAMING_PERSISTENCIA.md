# Arquitetura - Streaming de Respostas e Persist√™ncia de Hist√≥rico

**Arquiteto:** Winston (Architect)  
**Data:** 2025-01-08  
**Solicitante:** Dev  

---

## üéØ OBJETIVOS

1. Implementar streaming de respostas (efeito m√°quina de escrever) para melhorar UX
2. Persistir √∫ltimas 5 mensagens da conversa no localStorage
3. Restaurar hist√≥rico ao recarregar p√°gina
4. Otimizar performance e experi√™ncia do usu√°rio

---

## üöÄ STREAMING DE RESPOSTAS

### Estrat√©gia: Token-by-Token com SSE (Server-Sent Events) ou Simula√ß√£o

**Op√ß√£o 1: SSE (Recomendado para produ√ß√£o)**
- Backend envia resposta via Server-Sent Events
- Frontend recebe tokens progressivamente
- Melhor experi√™ncia do usu√°rio

**Op√ß√£o 2: Simula√ß√£o (Implementa√ß√£o r√°pida)**
- Backend retorna resposta completa
- Frontend simula streaming token por token
- Mais simples de implementar

**Recomenda√ß√£o:** Implementar Op√ß√£o 2 primeiro (simula√ß√£o), depois migrar para SSE se necess√°rio.

### Implementa√ß√£o: Simula√ß√£o de Streaming

#### Backend: API Retorna Resposta Completa (sem mudan√ßas)
A API `/api/chat` continua retornando a resposta completa.

#### Frontend: Fun√ß√£o de Streaming

```javascript
async typewriterEffect(element, text, speed = 30) {
    // Limpa elemento
    element.textContent = '';
    
    // Cria span para anima√ß√£o
    const textSpan = document.createElement('span');
    element.appendChild(textSpan);
    
    // Adiciona caractere por caractere
    for (let i = 0; i < text.length; i++) {
        textSpan.textContent += text[i];
        
        // Pausa entre caracteres (velocidade adapt√°vel)
        await new Promise(resolve => setTimeout(resolve, speed));
        
        // Scroll autom√°tico durante digita√ß√£o
        if (i % 10 === 0) { // A cada 10 caracteres
            this.scrollToBottom();
        }
    }
    
    // Scroll final
    this.scrollToBottom();
}
```

#### Atualiza√ß√£o do addMessage:

```javascript
addMessage(content, sender, metadata = {}, useStreaming = true) {
    const messageElement = document.createElement('div');
    messageElement.className = `message ${sender}`;
    
    // ... c√≥digo de avatar, time, etc. ...
    
    const messageTextElement = document.createElement('div');
    messageTextElement.className = 'message-text';
    
    // Se for assistente e streaming habilitado, usa efeito m√°quina de escrever
    if (sender === 'assistant' && useStreaming) {
        // Renderiza estrutura primeiro
        messageElement.innerHTML = `
            <div class="message-avatar">ü§±</div>
            <div class="message-content">
                <div class="message-text"></div>
                ${categoryBadge}
                ${alertSection}
                <div class="message-time">${time}</div>
            </div>
        `;
        
        this.chatMessages.appendChild(messageElement);
        
        // Aplica streaming no elemento de texto
        const textElement = messageElement.querySelector('.message-text');
        this.typewriterEffect(textElement, content, 25); // 25ms por caractere
    } else {
        // Renderiza√ß√£o normal (instant√¢nea)
        messageTextElement.innerHTML = this.formatMessage(content);
        messageElement.innerHTML = `
            <div class="message-avatar">${avatar}</div>
            <div class="message-content">
                <div class="message-text">${this.formatMessage(content)}</div>
                ${categoryBadge}
                ${alertSection}
                <div class="message-time">${time}</div>
            </div>
        `;
        this.chatMessages.appendChild(messageElement);
    }
    
    this.scrollToBottom();
}
```

---

## üíæ PERSIST√äNCIA DE HIST√ìRICO

### Estrat√©gia: localStorage + √öltimas 5 Mensagens

#### Estrutura de Dados:

```javascript
{
    "chat_history": [
        {
            "content": "Como est√° o beb√™?",
            "sender": "user",
            "timestamp": "2025-01-08T10:30:00Z",
            "metadata": {}
        },
        {
            "content": "Oi! Que bom te ver por aqui! ...",
            "sender": "assistant",
            "timestamp": "2025-01-08T10:30:05Z",
            "metadata": {
                "fonte": "openai",
                "categoria": "saudacao"
            }
        }
        // ... at√© 5 mensagens (3 user + 2 assistant ou equivalente)
    ],
    "last_updated": "2025-01-08T10:30:05Z"
}
```

#### Fun√ß√µes de Persist√™ncia:

```javascript
// Salvar hist√≥rico
saveChatHistory() {
    try {
        const messages = Array.from(this.chatMessages.children)
            .slice(-5) // √öltimas 5 mensagens
            .map(msgEl => {
                const sender = msgEl.classList.contains('user') ? 'user' : 'assistant';
                const content = msgEl.querySelector('.message-text')?.textContent || '';
                const time = msgEl.querySelector('.message-time')?.textContent || '';
                
                return {
                    content: content,
                    sender: sender,
                    timestamp: new Date().toISOString(),
                    metadata: this.getMessageMetadata(msgEl) // Extrai categoria, etc.
                };
            });
        
        localStorage.setItem('sophia_chat_history', JSON.stringify({
            chat_history: messages,
            last_updated: new Date().toISOString()
        }));
        
        this.log('‚úÖ Hist√≥rico salvo no localStorage');
    } catch (error) {
        this.error('Erro ao salvar hist√≥rico:', error);
    }
}

// Carregar hist√≥rico
loadChatHistory() {
    try {
        const saved = localStorage.getItem('sophia_chat_history');
        if (!saved) return [];
        
        const data = JSON.parse(saved);
        
        // Verifica se hist√≥rico n√£o √© muito antigo (√∫ltimas 24h)
        const lastUpdated = new Date(data.last_updated);
        const now = new Date();
        const hoursSinceUpdate = (now - lastUpdated) / (1000 * 60 * 60);
        
        if (hoursSinceUpdate > 24) {
            // Hist√≥rico muito antigo, limpa
            localStorage.removeItem('sophia_chat_history');
            return [];
        }
        
        return data.chat_history || [];
    } catch (error) {
        this.error('Erro ao carregar hist√≥rico:', error);
        return [];
    }
}

// Restaurar hist√≥rico na tela
restoreChatHistory() {
    const history = this.loadChatHistory();
    
    if (history.length === 0) return;
    
    // Limpa mensagens atuais
    if (this.chatMessages) {
        this.chatMessages.innerHTML = '';
    }
    
    // Restaura mensagens (sem streaming, instant√¢neo)
    history.forEach(msg => {
        this.addMessage(msg.content, msg.sender, msg.metadata || {}, false); // false = sem streaming
    });
    
    // Scroll para o final
    this.scrollToBottom();
    
    this.log(`‚úÖ Hist√≥rico restaurado: ${history.length} mensagens`);
}
```

#### Integra√ß√£o:

```javascript
// No sendMessage(), ap√≥s receber resposta
// Salva hist√≥rico ap√≥s adicionar mensagem
this.saveChatHistory();

// No initMainApp(), ao inicializar
// Restaura hist√≥rico ao carregar
this.restoreChatHistory();
```

---

## üè∑Ô∏è SISTEMA DE TAGS DE CONTEXTO

### Implementa√ß√£o: Tags Passadas para OpenAI

#### Backend (j√° implementado):

```python
def _detectar_contexto_tags(self, pergunta, user_id):
    tags = []
    
    # Verifica crise emocional
    if user_id in SESSION_ALERT and SESSION_ALERT[user_id].get("ativo", False):
        tags.append("crise_emocional")
        nivel = SESSION_ALERT[user_id].get("nivel", "leve")
        tags.append(f"nivel_risco_{nivel}")
    
    # Detecta emo√ß√µes
    # ... c√≥digo de detec√ß√£o ...
    
    return tags
```

#### Integra√ß√£o no System Prompt:

As tags s√£o enviadas como parte do contexto para a OpenAI:

```
[Tags de Contexto: 
- crise_emocional
- nivel_risco_alto
- busca_apoio_emocional
]

[Contexto: ...]

Pergunta do usu√°rio
```

#### Ajuste do System Prompt para Usar Tags:

```
Voc√™ √© a Sophia, uma Intelig√™ncia Artificial EMP√ÅTICA...

**TAGS DE CONTEXTO:**
Quando receber tags de contexto, ajuste seu tom:

- **crise_emocional**: Priorize empatia, valida√ß√£o e orienta√ß√£o para ajuda profissional. 
  Seja EXTRA acolhedora e paciente.

- **celebra√ß√£o**: Seja entusiasmada e genuinamente feliz. Celebre com a m√£e!

- **cansa√ßo_extremo**: Valide o cansa√ßo, ofere√ßa suporte pr√°tico sem minimizar.

- **busca_orienta√ß√£o**: Forne√ßa informa√ß√µes claras e pr√°ticas, integrando dados 
  dispon√≠veis (vacinas, dicas, etc.).

- **d√∫vida_vacina**: Consulte o contexto da pr√≥xima vacina e forne√ßa informa√ß√µes precisas.

- **d√∫vida_amamenta√ß√£o**: Ofere√ßa orienta√ß√µes pr√°ticas baseadas na idade do beb√™.
```

---

## üé® CSS PARA STREAMING

### Efeito Visual Durante Streaming:

```css
.message.assistant .message-text.streaming {
    position: relative;
}

.message.assistant .message-text.streaming::after {
    content: '‚ñã';
    animation: blink 1s infinite;
    color: var(--color-primary-warm, #ff8fa3);
    margin-left: 2px;
}

@keyframes blink {
    0%, 50% { opacity: 1; }
    51%, 100% { opacity: 0; }
}
```

---

## üìä ESTRUTURA DE DADOS DE HIST√ìRICO

### localStorage Key: `sophia_chat_history`

```json
{
    "chat_history": [
        {
            "content": "Como est√° o beb√™?",
            "sender": "user",
            "timestamp": "2025-01-08T10:30:00.000Z",
            "metadata": {
                "categoria": null,
                "fonte": null
            }
        },
        {
            "content": "Oi! Que bom te ver...",
            "sender": "assistant",
            "timestamp": "2025-01-08T10:30:05.000Z",
            "metadata": {
                "categoria": "saudacao",
                "fonte": "openai"
            }
        }
    ],
    "last_updated": "2025-01-08T10:30:05.000Z"
}
```

---

## ‚úÖ CHECKLIST DE IMPLEMENTA√á√ÉO

### Streaming:
- [ ] Fun√ß√£o `typewriterEffect()` implementada
- [ ] `addMessage()` atualizado para usar streaming
- [ ] CSS para cursor piscante durante streaming
- [ ] Scroll autom√°tico durante digita√ß√£o
- [ ] Velocidade ajust√°vel (r√°pida/lenta)

### Persist√™ncia:
- [ ] Fun√ß√£o `saveChatHistory()` implementada
- [ ] Fun√ß√£o `loadChatHistory()` implementada
- [ ] Fun√ß√£o `restoreChatHistory()` implementada
- [ ] Limpeza autom√°tica de hist√≥rico antigo (>24h)
- [ ] Integra√ß√£o no `sendMessage()` e `initMainApp()`

### Tags de Contexto:
- [x] Fun√ß√£o `_detectar_contexto_tags()` implementada
- [x] Tags enviadas para OpenAI
- [ ] System Prompt atualizado para usar tags
- [ ] Testes com diferentes contextos

---

## üîÑ FLUXO COMPLETO

1. **Usu√°rio envia mensagem**
2. **Frontend**: Mostra typing indicator
3. **Backend**: Processa, detecta tags, busca contexto
4. **Backend**: Retorna resposta completa
5. **Frontend**: Remove typing, aplica streaming
6. **Frontend**: Salva no hist√≥rico (localStorage)
7. **Usu√°rio recarrega p√°gina**
8. **Frontend**: Restaura √∫ltimas 5 mensagens

---

**Arquitetura criada por:** Winston (Architect)  
**Data:** 2025-01-08  
**Vers√£o:** 1.0
